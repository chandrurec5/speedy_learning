\section{Stochastic Approximation}
In a variety of scenarios such as stochastic optimization and RL, algorithms perform on-line parameter tuning based on observations corrupted by noise. Such algorithms are called stochastic approximation algorithms, where the term stochastic signifies the fact that the noisy observations are stochastically approximate and are equal to the true values in expectation. A characteristic of SA algorithms is incremental updates, wherein, at each iteration, the parameter is updated by making small step in the right direction. By carefully selecting the step-sizes and increment directions, SA algorithms converge to the optimal parameter. We now present the main results in SA theory that will be of interest to us.\par
A typical single\footnote{Actor-Critic RL algorithms might use multiple timescales, i.e., different step-size for different parameters. However, we are interested only in policy evaluation and would like to restrict ourselves to single timescale schemes.} timescale SA algorithm is given by 
\begin{align}\label{sa}
x_{t+1}=x_t+\alpha_t(f(x_t)+M_{t+1}),
\end{align}
where $x_t\in \R^n, \forall t\geq 0$ are the iterates of the algorithm, $f\colon \R^n \ra \R^n$ is the true observation, $\{\alpha_t\},t\geq 0$ is the step-size schedule and $\{M_{t+1}\}, t\geq 0$ are martingale difference noise terms. Further, it is also quite common practice in SA theory to assume the following:
\begin{assumption}\label{saassump}\hspace{10pt}\\
\vspace{-20pt}
\begin{enumerate}[leftmargin=*]
\item\label{lip} $f$ is Lipschitz continuous.
\item\label{stp} $\alpha_t\ra 0, t\ra\infty$, $\sum_{t\geq 0}\alpha_t =\infty$ and $\sum_{t\geq 0}\alpha^2_t <\infty$.
\item\label{mart} $\{M_t\}$ is a martingale difference sequence with respect to an increasing family of $\sigma$-fields $\mathcal{F}_t\stackrel{\cdot}{=}\sigma(x_0,M_1,\ldots,M_t),t\geq 0$, such that
$
\E[M_{t+1}|\F_t]=0~\text{a.s.}, t\geq 0
$. Further, $\{M_t\}$ are square-integrable i.e., $\E[M_{t+1}|\F_t]\leq K(1+\parallel x_t\parallel^2), a.s., \forall t\geq 0$.
\item\label{bdd} $\sup_t\parallel x_t \parallel<\infty$
\item\label{stab} The ordinary differential equation (ODE) $\dot{x}(s)=f(x(s)), s\geq 0$, has a globally unique asymptotically stable equilibrium $x^*\in \R^n$.
\end{enumerate}\end{assumption}
A typical step-size schedule that satisfies \ref{stp} is $\alpha_t=C/t$. In short \ref{stp} requires the step-sizes to be diminishing, and square summable. In \ref{mart} $\mathcal{F}_t$, denotes the history of the algorithm. The square integrability condition in \ref{mart} along with diminishing step-sizes in \ref{stp} and boundedness of the iterates enables the asymptotic analysis to discard noise. Once the noise is discarded in the limit, the SA algorithm can then be studied by analyzing the ODE defined in \ref{stab}. The boundedness is not limiting in practice and can be ensured by projecting the iterates of the algorithm onto a large compact set.\par
The formal result in SA theory (please see \cite{SA} for more details) under \Cref{saassump} is state below:
\begin{theorem}\label{sat}
Let $x(s),s\geq 0$ denote the solution to the ODE $\dot{x}(s)=f(x(s))$, with $x(0)=x_0$ and let $s(t)\sum_{0\leq k< t}\alpha_k$. Under the above assumptions we have iterates $x_t\ra x(s(t))$ as $t\ra\infty$ and $x_t\ra x^*$.
\end{theorem}
\subsection{Linear SA algorithms}
By a linear SA (LSA) algorithm with design $\D=\langle g,H\rangle$ in $n$ variables we mean the following:
\begin{align}\label{linearrec}
x_{t+1}=x_t+\alpha_t(g-H_t x_t)+\alpha_t N_{t+1},
\end{align}
where $x_t\in \R^n$ are the iterates, $H_t\in \R^{n\times n}$ are i.i.d matrices with $\E[H_t]=H$ (the design matrix), $g\in \R^n$ is the design vector and $N_{t+1}$ are martingale difference term such that $\E[\parallel N_{t+1} \parallel^2]\leq \sigma^2$ for some $\sigma\in \R^+$. Note that the LSA in \eqref{linearrec} can be re-written as 
\begin{align}\label{linearrecadd}
x_{t+1}=x_t+\alpha_t(g-H x_t)+\alpha_t M_{t+1},
\end{align}
where $M_{t+1}=N_{t+1}+(H-H_t)x_t$. It is easy to check that when all the entries of $H_t$ are bounded, condition~\ref{mart} of \Cref{saassump} holds for $M_{t+1}$ in \eqref{linearrecadd}.
In the next section, we will show that several TD algorithm are SA algorithm with different designs. 
It is trivial to check (and ensure) that conditions \ref{lip}-\ref{bdd} of \Cref{saassump} hold for linear SA algorithm. The convergence result for linear SA algorithms can be stated as 
a direct consequence of \Cref{saassump}~\ref{stab} and \Cref{sat}.
\begin{corollary}\label{linstab}
The iterates $x_t\in \R^n$ in the linear stochastic update rule in \eqref{linearrec} converge $x^*=H^{-1}g$ as $t\ra\infty $iff $H$ is positive definite.
\end{corollary}
We denote the spectrum of design matrix by $\{\mu_i,i=1,\ldots,n\}$.
\subsection{Insights on Forgetting Bias}
The SA theory via the ODE analysis throws light on the rate at which the initial bias (i.e., $x_0$) is forgotten. It is know from standard results in linear system theory that the trajectory $x(s),s\geq 0$ of the ODE $\dot{x}(s)=(g-Hx(s))$ is given by
\begin{align}\label{oderate}
x(s)=\sum_{i=1}^n \zeta_i e^{-\mu_i s}, 
\end{align}
where $\zeta=(\zeta_i,i=1,\ldots,n)\in \R^n$ are real coefficients. The time $s\geq 0$ in \eqref{oderate} is \emph{real} time and the time corresponding to the $t^{th}$ iterate of the algorithm is roughly $s(t)\approx\sum_{0\leq k<t}\alpha_t$. It is easy to see from \eqref{oderate} that the rate of forgetting initial conditions depends on the Eigen values values and the accumulation of algorithm time. For instance, if the step-size are chosen to be $\alpha_t=C/t$, then \begin{align}\label{biasforget}e^{-\mu_i\sum_{0\leq k<t}\alpha_t}\approx e^{-\mu_i Clog s}=O(1/s^{\mu_i C})\end{align}
It is clear that the forgetting the initial condition depends both on the step-sizes which dictates accumulation of time i.e., $\sum_{0\leq k<t}\alpha_t$ and the condition number of the design matrix. 
\subsection{Noisy Discretization Schemes}
The idea of using ODEs is not restricted to just analysis, and can extend to synthesis, i.e., new SA algorithms can be obtained as noisy discretization of ODEs (which converges to the desired solution). Discretization is a common theme in numerical solution methods to solve ODEs, and of particular interest are the Euler discretization and the \emph{predictor-corrector} discretization schemes. Given an ODE $\dot{x}(t)=(g-Hx(t))$, the noisy Euler discretization is given in \eqref{linearrec} and the noisy PC discretization is given by
\begin{align}\label{PC}
\begin{split}
x^m_{t}&=x_t+\alpha_t(g-Hx_t)\\
x_{t+1}&=x_t+\alpha_t(g-Hx^m_t)
\end{split}
\end{align}
The idea behind the PC method is to first take a step in the gradient direction to produce a new point $x^m_t$, and then obtain the estimate of the gradient at $x^m_t$ to be used to update $x_t$. Notice that the PC updates can be unfurled and written as the following single recursion
\begin{align*}
\begin{split}
x_{t+1}&=x_t+\alpha_t(g-H(x_t+\alpha_t(g-Hx_t)))\\
&=x_t+\alpha_t(g+\alpha_t g- H +\alpha_t H^2)x_t \\
&= (I-\alpha_t H+\alpha_t^2 H^2)x_t+\alpha_t(g-\alpha_t H g)
\end{split}
\end{align*}