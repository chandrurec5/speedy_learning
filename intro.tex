\section{Introduction}
We are interested in understanding the finite time behaviour of the linear stochastic approximation (LSA) algorithm given by $x_{t+1}=x_t+\alpha_t(g_t-H_t)x_n$, where $x_t\in \R^n$ are the iterates, $\{\alpha_t\geq 0\}$ is the step-size rule, $g_t\in \R^n$ and $H_t\in \R^{n\times n}$ are \emph{noisy} samples of a design vector $g\in\R^n$ and a design matrix $H\in\R^{n\times n}$ respectively, i.e., $\E[g_t]=g$ and $\E[H_t]=H$. The LSA algorithm is quite common in scenarios where only access to noisy samples of true quantities is available. In this paper, we intend to study the finite time performance of the LSA algorithm.\par
The motivation for our study is the problem of \emph{value function} estimation in reinforcement learning (RL), wherein we are required to estimate the value function corresponding to a Markov reward process\footnote{Please refer \cite{BertB} for a detailed background}. A particular aspect of the RL setting is that the explicit model of the Markov reward process is not known and only data in the form of samples is made available. Thus value function learning algorithms in the RL setting are mostly LSA algorithms. A critical issue related the finite time performance of the LSA algorithms is the step-size rule which dictates the stability of the algorithm as well as the rate of convergence. 
\par
Our work is inspired by a related work in \cite{bachaistats}, in which the authors consider the problem of linear prediction with the penalty function as quadratic loss under an i.i.d  (with respect to some unknown distribution) assumption on the data. The linear prediction problem in \cite{bachaistats} is solved by an stochastic gradient descent (SGD) algorithm which is an LSA algorithm as well. In \cite{bachaistats}, the finite time error is split into two terms namely the bias term (due to the initial condition) and the variance term (due to noise). Rupert-Polyak (RP) averaging is revisited in \cite{bachaistats}, to show that, under a constant step-size rule with iterate averaging, a finite time performance of $O(1/t^2)$ and $O(1/t)$ respectively for the bias and the variance terms can be achieved. An important difference in our case is that unlike the linear prediction setting, the matrices $H/H_t$ are not symmetric in the RL setting. We nevertheless show that analysis on the lines of \cite{bachaistats} still holds for the LSAs in the RL setting, thereby presenting an analysis under more generalized assumptions i.e., in the absence of symmetry.\par
The \emph{temporal difference} (TD) family of RL algorithms are value function learning algorithms. The term \emph{temporal difference} stands for the  error in the estimate of the value function obtained as a difference of terms involving the values in the successive states. The TD algorithms are LSA algorithms and are popular in applications where only $O(n)$ computations are desired per time step. Stability and rate of convergence have been the two most important aspects that have been considered in the development of the various TD algorithms. While almost all the TD algorithms of interest make use of linear updates, the design of these update rules are ad-hoc \cite{gtdfinite}, thereby lacking a systematic methodology. Our work presents a refined view of the TD algorithms on two accounts. Firstly, our analysis show that most of the TD algorithms achieve rates of convergence faster than previously believed. Secondly, we show that the choice of the update rule can be appreciated better by looking at the spectral properties of the corresponding design matrix. The analysis shows that there is no clear winner amongst the various TD algorithms and different algorithms can be better for different Markov reward processes.\par
The specific contributions in this paper are listed as below
\begin{itemize}[leftmargin=*] 
\item We show (in \Cref{main result}) that LSA algorithms with constant step-size rule and RP averaging achieve $O(1/t^2)$ for forgetting the initial bias and $O(1/t)$ rate (\Cref{maintheorem}) for the variance.
\item We show specific counter examples (\Cref{opti}) to refute the conjecture in \cite{bachaistats} on the maximum allowable constant step-size for LSA algorithms.
\item We discuss how the performance of the various TD algorithms can be understood by analyzing the spectral properties of the design matrix. For the purpose of illustrating our view, we introduce (\Cref{design}) and analyze certain newer TD variants.
\end{itemize}
We also present numerical examples along side the analysis.
