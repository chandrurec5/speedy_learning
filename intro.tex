\section{Introduction}
We are interested in understanding the finite time behaviour of the linear stochastic approximation (LSA) given by $x_{t+1}=x_t+\alpha_t(g_t-H_t)x_n$, where $x_t\in \R^n$ are the iterates, $\{\alpha_t\geq 0\}$ is the step-size rule, $g_t\in \R^n$ and $H_t\in \R^{n\times n}$ are \emph{noisy} samples of a design vector $b$ and a design matrix $H$ respectively, i.e., $\E[g_t]=g$ and $\E[H_t]=H$. The LSA recursion is quite common in scenarios where the algorithm has only access to noisy samples of true quantities. We intend to study the finite time performance of such algorithms.\par
The motivation to study the problem is \emph{value function} estimation in reinforcement learning, wherein we are required to estimate the value function corresponding to a Markov reward process\footnote{Please refer \cite{} for a detailed background}. A particular aspect of the RL setting is that the explicit model of the Markov reward process is not known and only data in the form of samples is made available. Thus value function learning algorithms in the RL setting are mostly LSA algorithms. A critical issue related the finite time performance of the LSA algorithms is the step-size rule which dictates the stability of the algorithm as well as the rate of convergence. 
\par
Our work is inspired by a related work in \cite{}, in which the authors consider the problem of linear prediction with the penalty function as quadratic loss under an i.i.d  (with respect to some unknown distribution) on data. The linear prediction problem in \cite{} is solved by an stochastic gradient descent algorithm which is an LSA algorithm as well. In \cite{}, the finite time error is split into two terms namely the bias term (due to the initial condition) and the variance term (due to noise). Rupert-Polyak averaging is revisited in \cite{}, to show that, under a constant step-size rule with iterate averaging, a finite time performance of $O(1/t^2)$ and $O(1/t)$ respectively on bias and variance terms can be achieved. An important difference in our case is that unlike the linear prediction setting, the matrices $H/H_t$ are not symmetric in the RL setting. We nevertheless show that analysis on the lines of \cite{} still holds for the LSAs in the RL setting, thereby presenting an analysis under more generalized assumptions i.e., in the absence of symmetry.\par
The \emph{temporal difference} (TD) family of RL algorithms are value function learning algorithms. The term \emph{temporal difference} stands for the  error in the estimate of the value function obtained as a difference of terms involving the values in the successive states. The TD algorithms are LSA algorithms and are desired in application where only $O(n)$ computations are desired per time step. Stability and rate of convergence have been the two most important aspects that have been considered in the development of various TD algorithms. While almost all TD algorithms of interest make use of linear updates, the design of the update rule is ad-hoc \cite{}, thereby lacking a systematic methodology. Our work presents a refined view of the TD algorithms on two accounts. Firstly, our analysis show that the most of the TD algorithm achieve rates of convergence faster than previously believed. Secondly, we show that the choice of the update rule can be appreciated better by looking at the spectral properties of the corresponding design matrix. The analysis shows that there is no clear winner amongst the various TD algorithms and different algorithms can be better for different Markov reward processes.\par
The specific contributions in this paper are listed as below
\begin{itemize}[leftmargin=*] 
\item We show (in \Cref) that LSA algorithms with constant step-size rule and RP iterate averaging achieve $O(1/t^2)$ for forgetting initial conditions and $O(1/t)$ rate (\Cref) for variance term.
\item We show specific counter example to refute the conjecture in \cite{} on the maximum allowable constant step-size.
\item We discuss how the performance of the various TD algorithms can be understood by analyzing the spectral properties of the design matrix. For the purpose of illustrating our view, we introduce and analyze certain newer TD variants.
\end{itemize}
We also present numerical examples along side the analysis.
