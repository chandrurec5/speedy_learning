\section{Synthesis of New algorithms}
\subsection{Stories of Failures}

\subsection{Stories of Success}
Consider the ODE given by
\begin{align}
\dot{x}(t)=(g-Hx(t))
\end{align}
with initial condition $x(0)=x_0$. The Euler discretization of the above ODE leads to the following update rule
\begin{align}\label{euler}
x_{t+1}=x_t+\alpha_t(g-Hx_t).
\end{align}
The \emph{Predictor-Corrector} discretization of the ODE is the following update rule
\begin{align}
x^m_{t}&=x_t+\alpha_t(g-Hx_t)\\
x_{t+1}&=x_t+\alpha_t(g-Hx^m_t)
\end{align} 
The idea behind the PC method is to first take a step in the gradient direction to produce a new point $x^m_t$, and then obtain the estimate of the gradient at $x^m_t$ to be used to update $x_t$. It is clear that the GTD-MP is using the PC type update. Notice that the PC updates can be unfurled and written as the following single recursion
\begin{align}
x_{t+1}&=x_t+\alpha_t(g-H(x_t+\alpha_t(g-Hx_t)))\\
&=x_t+\alpha_t(g+\alpha_t g- H +\alpha_t H^2)x_t \\
&= (I-\alpha_t H+\alpha_t^2 H^2)x_t+\alpha_t(g-\alpha_t H g)
\end{align}
Notice that the PC method is slower than the Euler discretization in \eqref{euler}.
